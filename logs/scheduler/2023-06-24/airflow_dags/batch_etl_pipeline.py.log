[2023-06-24T21:02:46.107+0000] {processor.py:154} INFO - Started process (PID=182) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:02:46.109+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:02:46.110+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:02:46.110+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:02:47.099+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:02:47.095+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:02:47.102+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:02:47.120+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 1.015 seconds
[2023-06-24T21:05:03.588+0000] {processor.py:154} INFO - Started process (PID=181) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:05:03.590+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:05:03.592+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:05:03.592+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:05:04.577+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:05:04.573+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:05:04.580+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:05:04.604+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 1.020 seconds
[2023-06-24T21:05:34.932+0000] {processor.py:154} INFO - Started process (PID=215) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:05:34.935+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:05:34.936+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:05:34.936+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:05:35.378+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:05:35.373+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:05:35.381+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:05:35.402+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.476 seconds
[2023-06-24T21:06:05.991+0000] {processor.py:154} INFO - Started process (PID=248) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:06:05.994+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:06:05.997+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:06:05.997+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:06:06.504+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:06:06.498+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:06:06.506+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:06:06.524+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.540 seconds
[2023-06-24T21:06:36.879+0000] {processor.py:154} INFO - Started process (PID=279) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:06:36.881+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:06:36.883+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:06:36.883+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:06:37.137+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:06:37.132+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:06:37.139+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:06:37.159+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.284 seconds
[2023-06-24T21:07:07.359+0000] {processor.py:154} INFO - Started process (PID=304) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:07:07.362+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:07:07.364+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:07:07.364+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:07:07.729+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:07:07.724+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:07:07.732+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:07:07.754+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.402 seconds
[2023-06-24T21:07:37.839+0000] {processor.py:154} INFO - Started process (PID=337) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:07:37.841+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:07:37.842+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:07:37.842+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:07:38.021+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:07:38.016+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:07:38.022+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:07:38.040+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.203 seconds
[2023-06-24T21:07:44.150+0000] {processor.py:154} INFO - Started process (PID=352) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:07:44.155+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:07:44.157+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:07:44.156+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:07:44.470+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:07:44.465+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:07:44.472+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:07:44.497+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.353 seconds
[2023-06-24T21:08:14.890+0000] {processor.py:154} INFO - Started process (PID=376) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:08:14.894+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:08:14.897+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:08:14.897+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:08:15.220+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:08:15.215+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:08:15.223+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:08:15.260+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.376 seconds
[2023-06-24T21:08:45.685+0000] {processor.py:154} INFO - Started process (PID=409) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:08:45.688+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:08:45.690+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:08:45.690+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:08:46.019+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:08:46.009+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:08:46.023+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:08:46.058+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.379 seconds
[2023-06-24T21:09:16.409+0000] {processor.py:154} INFO - Started process (PID=442) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:09:16.412+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:09:16.416+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:09:16.416+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:09:17.078+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:09:17.074+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:09:17.080+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:09:17.100+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.695 seconds
[2023-06-24T21:09:47.381+0000] {processor.py:154} INFO - Started process (PID=474) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:09:47.384+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:09:47.386+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:09:47.386+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:09:47.891+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:09:47.886+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:09:47.896+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:09:47.912+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.537 seconds
[2023-06-24T21:10:18.345+0000] {processor.py:154} INFO - Started process (PID=507) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:10:18.350+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:10:18.353+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:10:18.353+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:10:18.656+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:10:18.651+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:10:18.660+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:10:18.681+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.340 seconds
[2023-06-24T21:10:49.097+0000] {processor.py:154} INFO - Started process (PID=540) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:10:49.100+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:10:49.102+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:10:49.102+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:10:49.394+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:10:49.388+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:10:49.396+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:10:49.418+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.328 seconds
[2023-06-24T21:11:19.774+0000] {processor.py:154} INFO - Started process (PID=572) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:11:19.776+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:11:19.779+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:11:19.779+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:11:20.000+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:11:19.993+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:11:20.001+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:11:20.029+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.258 seconds
[2023-06-24T21:11:50.241+0000] {processor.py:154} INFO - Started process (PID=596) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:11:50.244+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:11:50.245+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:11:50.245+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:11:50.532+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:11:50.526+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:11:50.535+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:11:50.554+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.319 seconds
[2023-06-24T21:12:20.997+0000] {processor.py:154} INFO - Started process (PID=631) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:12:21.000+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:12:21.002+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:12:21.002+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:12:21.222+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:12:21.217+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:12:21.223+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:12:21.501+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.508 seconds
[2023-06-24T21:12:51.997+0000] {processor.py:154} INFO - Started process (PID=663) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:12:52.000+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:12:52.001+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:12:52.001+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:12:52.526+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:12:52.521+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:12:52.527+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:12:52.545+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.552 seconds
[2023-06-24T21:13:22.741+0000] {processor.py:154} INFO - Started process (PID=695) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:13:22.745+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:13:22.748+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:13:22.748+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:13:23.091+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:13:23.084+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:13:23.096+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:13:23.115+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.379 seconds
[2023-06-24T21:13:53.224+0000] {processor.py:154} INFO - Started process (PID=735) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:13:53.227+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:13:53.230+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:13:53.229+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:13:53.759+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:13:53.754+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:13:53.763+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:13:53.780+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.561 seconds
[2023-06-24T21:14:24.162+0000] {processor.py:154} INFO - Started process (PID=758) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:14:24.164+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:14:24.167+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:14:24.167+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:14:24.415+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:14:24.409+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:14:24.417+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:14:24.438+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.282 seconds
[2023-06-24T21:14:54.559+0000] {processor.py:154} INFO - Started process (PID=794) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:14:54.562+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:14:54.565+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:14:54.564+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:14:54.872+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:14:54.865+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:14:54.874+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:14:54.894+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.340 seconds
[2023-06-24T21:15:25.184+0000] {processor.py:154} INFO - Started process (PID=827) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:15:25.188+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:15:25.190+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:15:25.190+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:15:25.394+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:15:25.388+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:15:25.397+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:15:25.414+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.236 seconds
[2023-06-24T21:15:55.566+0000] {processor.py:154} INFO - Started process (PID=861) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:15:55.569+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:15:55.571+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:15:55.571+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:15:55.859+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:15:55.853+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:15:55.861+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:15:56.113+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.552 seconds
[2023-06-24T21:16:26.284+0000] {processor.py:154} INFO - Started process (PID=895) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:16:26.287+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:16:26.289+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:16:26.289+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:16:26.602+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:16:26.597+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:16:26.604+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:16:26.618+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.339 seconds
[2023-06-24T21:16:56.949+0000] {processor.py:154} INFO - Started process (PID=928) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:16:56.951+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:16:56.954+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:16:56.954+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:16:57.554+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:16:57.548+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:16:57.557+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:16:57.575+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.630 seconds
[2023-06-24T21:18:28.352+0000] {processor.py:154} INFO - Started process (PID=181) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:18:28.356+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:18:28.360+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:18:28.359+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:18:29.317+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:18:29.311+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:18:29.320+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:18:29.338+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.989 seconds
[2023-06-24T21:18:59.640+0000] {processor.py:154} INFO - Started process (PID=214) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:18:59.642+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:18:59.644+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:18:59.644+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:19:00.126+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:19:00.120+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:19:00.128+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:19:00.147+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.510 seconds
[2023-06-24T21:19:30.555+0000] {processor.py:154} INFO - Started process (PID=247) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:19:30.557+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:19:30.559+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:19:30.559+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:19:31.216+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:19:31.209+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:19:31.221+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:19:31.246+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.695 seconds
[2023-06-24T21:20:01.640+0000] {processor.py:154} INFO - Started process (PID=271) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:20:01.644+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:20:01.647+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:20:01.647+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:20:02.251+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:20:02.246+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:20:02.254+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:20:02.272+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.638 seconds
[2023-06-24T21:20:32.717+0000] {processor.py:154} INFO - Started process (PID=303) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:20:32.720+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:20:32.723+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:20:32.723+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:20:33.290+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:20:33.284+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:20:33.292+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:20:33.317+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.608 seconds
[2023-06-24T21:21:03.823+0000] {processor.py:154} INFO - Started process (PID=337) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:21:03.828+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:21:03.830+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:21:03.829+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:21:04.453+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:21:04.447+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:21:04.455+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:21:04.479+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.662 seconds
[2023-06-24T21:21:34.906+0000] {processor.py:154} INFO - Started process (PID=370) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:21:34.909+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:21:34.911+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:21:34.911+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:21:35.175+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:21:35.170+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:21:35.179+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:21:35.425+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.523 seconds
[2023-06-24T21:22:05.598+0000] {processor.py:154} INFO - Started process (PID=403) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:22:05.601+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:22:05.603+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:22:05.603+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:22:06.073+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:22:06.068+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:22:06.077+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:22:06.095+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.502 seconds
[2023-06-24T21:22:36.461+0000] {processor.py:154} INFO - Started process (PID=436) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:22:36.465+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:22:36.467+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:22:36.467+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:22:36.949+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:22:36.943+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:22:36.951+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:22:36.967+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.512 seconds
[2023-06-24T21:23:07.345+0000] {processor.py:154} INFO - Started process (PID=460) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:23:07.348+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:23:07.349+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:23:07.349+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:23:07.912+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:23:07.906+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:23:07.915+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:23:07.933+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.592 seconds
[2023-06-24T21:23:21.238+0000] {processor.py:154} INFO - Started process (PID=485) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:23:21.245+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:23:21.248+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:23:21.248+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:23:21.794+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:23:21.790+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:23:21.798+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:23:21.814+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.580 seconds
[2023-06-24T21:23:52.146+0000] {processor.py:154} INFO - Started process (PID=510) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:23:52.149+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:23:52.150+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:23:52.150+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:23:52.803+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:23:52.797+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:23:52.805+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:23:52.832+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.690 seconds
[2023-06-24T21:24:23.232+0000] {processor.py:154} INFO - Started process (PID=544) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:24:23.237+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:24:23.239+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:24:23.239+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:24:23.794+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:24:23.786+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:24:23.796+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:24:23.817+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.594 seconds
[2023-06-24T21:24:54.349+0000] {processor.py:154} INFO - Started process (PID=577) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:24:54.353+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:24:54.356+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:24:54.356+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:24:54.945+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:24:54.937+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:24:54.948+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:24:54.966+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.625 seconds
[2023-06-24T21:25:25.372+0000] {processor.py:154} INFO - Started process (PID=609) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:25:25.375+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:25:25.377+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:25:25.377+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:25:25.934+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:25:25.928+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:25:25.938+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:25:25.959+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.591 seconds
[2023-06-24T21:25:56.156+0000] {processor.py:154} INFO - Started process (PID=642) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:25:56.160+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:25:56.165+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:25:56.165+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:25:56.694+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:25:56.690+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:25:56.696+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:25:56.713+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.563 seconds
[2023-06-24T21:26:22.464+0000] {processor.py:154} INFO - Started process (PID=666) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:26:22.467+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:26:22.469+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:26:22.469+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:26:23.045+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:26:23.038+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:26:23.049+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:26:23.066+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.607 seconds
[2023-06-24T21:26:24.067+0000] {processor.py:154} INFO - Started process (PID=672) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:26:24.069+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:26:24.071+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:26:24.071+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:26:24.349+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:26:24.343+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:26:24.352+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:26:24.367+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.305 seconds
[2023-06-24T21:27:28.328+0000] {processor.py:154} INFO - Started process (PID=181) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:27:28.333+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:27:28.335+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:27:28.335+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:27:29.273+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:27:29.267+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:27:29.275+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:27:29.292+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.968 seconds
[2023-06-24T21:27:59.605+0000] {processor.py:154} INFO - Started process (PID=213) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:27:59.607+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:27:59.610+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:27:59.610+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:28:00.113+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:28:00.106+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:28:00.115+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:28:00.136+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.538 seconds
[2023-06-24T21:28:30.523+0000] {processor.py:154} INFO - Started process (PID=244) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:28:30.525+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:28:30.526+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:28:30.526+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:28:31.104+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:28:31.098+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:28:31.108+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:28:31.129+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.610 seconds
[2023-06-24T21:29:01.538+0000] {processor.py:154} INFO - Started process (PID=270) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:29:01.541+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:29:01.543+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:29:01.543+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:29:01.801+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:29:01.795+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:29:01.803+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:29:01.825+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.292 seconds
[2023-06-24T21:29:32.243+0000] {processor.py:154} INFO - Started process (PID=303) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:29:32.245+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:29:32.247+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:29:32.247+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:29:32.438+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:29:32.434+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:29:32.440+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:29:32.457+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.218 seconds
[2023-06-24T21:30:02.604+0000] {processor.py:154} INFO - Started process (PID=335) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:30:02.607+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:30:02.608+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:30:02.608+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:30:02.890+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:30:02.885+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:30:02.893+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:30:02.914+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.315 seconds
[2023-06-24T21:30:33.101+0000] {processor.py:154} INFO - Started process (PID=368) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:30:33.104+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:30:33.106+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:30:33.106+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:30:33.410+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:30:33.397+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:30:33.413+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:30:33.436+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.344 seconds
[2023-06-24T21:31:03.559+0000] {processor.py:154} INFO - Started process (PID=400) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:31:03.562+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:31:03.565+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:31:03.565+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:31:04.003+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:31:03.994+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:31:04.004+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:31:04.029+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.475 seconds
[2023-06-24T21:31:34.349+0000] {processor.py:154} INFO - Started process (PID=424) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:31:34.352+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:31:34.355+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:31:34.355+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:31:35.001+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:31:34.997+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:31:35.004+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:31:35.024+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.679 seconds
[2023-06-24T21:32:05.520+0000] {processor.py:154} INFO - Started process (PID=457) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:32:05.523+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:32:05.524+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:32:05.524+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:32:06.054+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:32:06.049+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:32:06.056+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:32:06.074+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.558 seconds
[2023-06-24T21:32:36.578+0000] {processor.py:154} INFO - Started process (PID=490) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:32:36.581+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:32:36.583+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:32:36.583+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:32:36.934+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:32:36.928+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:32:36.936+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:32:36.959+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.386 seconds
[2023-06-24T21:33:07.428+0000] {processor.py:154} INFO - Started process (PID=523) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:33:07.430+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:33:07.432+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:33:07.432+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:33:07.816+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:33:07.811+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:33:07.818+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:33:07.840+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.418 seconds
[2023-06-24T21:33:38.143+0000] {processor.py:154} INFO - Started process (PID=556) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:33:38.146+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:33:38.148+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:33:38.148+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:33:39.162+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:33:39.151+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:33:39.165+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:33:39.201+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 1.062 seconds
[2023-06-24T21:34:09.482+0000] {processor.py:154} INFO - Started process (PID=579) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:34:09.486+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:34:09.491+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:34:09.490+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:34:09.863+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:34:09.857+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:34:09.866+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:34:09.894+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.418 seconds
[2023-06-24T21:34:40.398+0000] {processor.py:154} INFO - Started process (PID=612) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:34:40.403+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:34:40.405+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:34:40.405+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:34:40.770+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:34:40.765+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
  File "/opt/airflow/dags/scripts/load_to_postgres_staging.py", line 4, in <module>
    orders_df = pd.read_csv('/opt/airflow/data/orders.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 586, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 482, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 811, in __init__
    self._engine = self._make_engine(self.engine)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/readers.py", line 1040, in _make_engine
    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 51, in __init__
    self._open_handles(src, kwds)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py", line 229, in _open_handles
    errors=kwds.get("encoding_errors", "strict"),
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 707, in get_handle
    newline="",
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/orders.csv'
[2023-06-24T21:34:40.772+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:34:41.163+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.774 seconds
[2023-06-24T21:35:11.523+0000] {processor.py:154} INFO - Started process (PID=645) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:35:11.561+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:35:11.563+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:35:11.563+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:35:12.133+0000] {logging_mixin.py:137} INFO - hello
[2023-06-24T21:35:12.137+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:35:12.135+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
ImportError: cannot import name 'write_raw' from 'scripts.load_to_postgres_staging' (/opt/airflow/dags/scripts/load_to_postgres_staging.py)
[2023-06-24T21:35:12.141+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:35:12.157+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.639 seconds
[2023-06-24T21:36:09.119+0000] {processor.py:154} INFO - Started process (PID=189) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:36:09.127+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:36:09.129+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:36:09.129+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:36:10.021+0000] {logging_mixin.py:137} INFO - hello
[2023-06-24T21:36:10.031+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:36:10.025+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
ImportError: cannot import name 'write_raw' from 'scripts.load_to_postgres_staging' (/opt/airflow/dags/scripts/load_to_postgres_staging.py)
[2023-06-24T21:36:10.033+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:36:10.053+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.938 seconds
[2023-06-24T21:36:40.474+0000] {processor.py:154} INFO - Started process (PID=222) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:36:40.482+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:36:40.485+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:36:40.485+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:36:41.167+0000] {logging_mixin.py:137} INFO - hello
[2023-06-24T21:36:41.172+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:36:41.169+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
ImportError: cannot import name 'write_raw' from 'scripts.load_to_postgres_staging' (/opt/airflow/dags/scripts/load_to_postgres_staging.py)
[2023-06-24T21:36:41.174+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:36:41.194+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.728 seconds
[2023-06-24T21:37:11.547+0000] {processor.py:154} INFO - Started process (PID=255) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:37:11.549+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:37:11.551+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:37:11.551+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:37:12.147+0000] {logging_mixin.py:137} INFO - hello
[2023-06-24T21:37:12.161+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:37:12.151+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
ImportError: cannot import name 'write_raw' from 'scripts.load_to_postgres_staging' (/opt/airflow/dags/scripts/load_to_postgres_staging.py)
[2023-06-24T21:37:12.163+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:37:12.181+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.639 seconds
[2023-06-24T21:37:42.805+0000] {processor.py:154} INFO - Started process (PID=281) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:37:42.807+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:37:42.810+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:37:42.810+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:37:43.218+0000] {logging_mixin.py:137} INFO - hello
[2023-06-24T21:37:43.228+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:37:43.220+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
ImportError: cannot import name 'write_raw' from 'scripts.load_to_postgres_staging' (/opt/airflow/dags/scripts/load_to_postgres_staging.py)
[2023-06-24T21:37:43.230+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:37:43.262+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.464 seconds
[2023-06-24T21:38:13.402+0000] {processor.py:154} INFO - Started process (PID=315) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:38:13.410+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:38:13.412+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:38:13.412+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:38:13.726+0000] {logging_mixin.py:137} INFO - hello
[2023-06-24T21:38:13.733+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:38:13.728+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
ImportError: cannot import name 'write_raw' from 'scripts.load_to_postgres_staging' (/opt/airflow/dags/scripts/load_to_postgres_staging.py)
[2023-06-24T21:38:13.736+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:38:13.758+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.365 seconds
[2023-06-24T21:38:44.027+0000] {processor.py:154} INFO - Started process (PID=349) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:38:44.030+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:38:44.034+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:38:44.034+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:38:44.369+0000] {logging_mixin.py:137} INFO - hello
[2023-06-24T21:38:44.376+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:38:44.370+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
ImportError: cannot import name 'write_raw' from 'scripts.load_to_postgres_staging' (/opt/airflow/dags/scripts/load_to_postgres_staging.py)
[2023-06-24T21:38:44.377+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:38:44.407+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.387 seconds
[2023-06-24T21:39:14.810+0000] {processor.py:154} INFO - Started process (PID=382) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:39:14.814+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:39:14.815+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:39:14.815+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:39:15.078+0000] {logging_mixin.py:137} INFO - hello
[2023-06-24T21:39:15.088+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:39:15.081+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
ImportError: cannot import name 'write_raw' from 'scripts.load_to_postgres_staging' (/opt/airflow/dags/scripts/load_to_postgres_staging.py)
[2023-06-24T21:39:15.090+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:39:15.114+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.307 seconds
[2023-06-24T21:39:45.269+0000] {processor.py:154} INFO - Started process (PID=415) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:39:45.274+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:39:45.277+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:39:45.277+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:39:45.590+0000] {logging_mixin.py:137} INFO - hello
[2023-06-24T21:39:45.596+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:39:45.592+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
ImportError: cannot import name 'write_raw' from 'scripts.load_to_postgres_staging' (/opt/airflow/dags/scripts/load_to_postgres_staging.py)
[2023-06-24T21:39:45.598+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:39:45.623+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.367 seconds
[2023-06-24T21:40:15.921+0000] {processor.py:154} INFO - Started process (PID=449) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:40:15.924+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:40:15.926+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:40:15.926+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:40:16.358+0000] {logging_mixin.py:137} INFO - hello
[2023-06-24T21:40:16.363+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:40:16.360+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
ImportError: cannot import name 'write_raw' from 'scripts.load_to_postgres_staging' (/opt/airflow/dags/scripts/load_to_postgres_staging.py)
[2023-06-24T21:40:16.365+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:40:16.383+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.467 seconds
[2023-06-24T21:40:46.866+0000] {processor.py:154} INFO - Started process (PID=472) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:40:46.870+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:40:46.872+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:40:46.872+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:40:47.585+0000] {logging_mixin.py:137} INFO - hello
[2023-06-24T21:40:47.590+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:40:47.587+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
ImportError: cannot import name 'write_raw' from 'scripts.load_to_postgres_staging' (/opt/airflow/dags/scripts/load_to_postgres_staging.py)
[2023-06-24T21:40:47.593+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:40:47.612+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.758 seconds
[2023-06-24T21:41:17.814+0000] {processor.py:154} INFO - Started process (PID=504) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:41:17.816+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:41:17.818+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:41:17.818+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:41:18.162+0000] {logging_mixin.py:137} INFO - hello
[2023-06-24T21:41:18.171+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:41:18.163+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
ImportError: cannot import name 'write_raw' from 'scripts.load_to_postgres_staging' (/opt/airflow/dags/scripts/load_to_postgres_staging.py)
[2023-06-24T21:41:18.172+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:41:18.193+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.386 seconds
[2023-06-24T21:41:48.375+0000] {processor.py:154} INFO - Started process (PID=537) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:41:48.377+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:41:48.379+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:41:48.379+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:41:48.656+0000] {logging_mixin.py:137} INFO - hello
[2023-06-24T21:41:48.664+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:41:48.658+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
ImportError: cannot import name 'write_raw' from 'scripts.load_to_postgres_staging' (/opt/airflow/dags/scripts/load_to_postgres_staging.py)
[2023-06-24T21:41:48.665+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:41:48.686+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.317 seconds
[2023-06-24T21:42:18.789+0000] {processor.py:154} INFO - Started process (PID=570) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:42:18.791+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:42:18.793+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:42:18.793+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:42:19.092+0000] {logging_mixin.py:137} INFO - hello
[2023-06-24T21:42:19.098+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:42:19.093+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
ImportError: cannot import name 'write_raw' from 'scripts.load_to_postgres_staging' (/opt/airflow/dags/scripts/load_to_postgres_staging.py)
[2023-06-24T21:42:19.099+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:42:19.118+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.337 seconds
[2023-06-24T21:42:49.565+0000] {processor.py:154} INFO - Started process (PID=594) to work on /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:42:49.569+0000] {processor.py:756} INFO - Processing file /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py for tasks to queue
[2023-06-24T21:42:49.572+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:42:49.572+0000] {dagbag.py:537} INFO - Filling up the DagBag from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:42:49.938+0000] {logging_mixin.py:137} INFO - hello
[2023-06-24T21:42:49.952+0000] {logging_mixin.py:137} INFO - [2023-06-24T21:42:49.946+0000] {dagbag.py:342} ERROR - Failed to import: /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 338, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/airflow_dags/batch_etl_pipeline.py", line 16, in <module>
    from scripts.load_to_postgres_staging import write_raw
ImportError: cannot import name 'write_raw' from 'scripts.load_to_postgres_staging' (/opt/airflow/dags/scripts/load_to_postgres_staging.py)
[2023-06-24T21:42:49.953+0000] {processor.py:768} WARNING - No viable dags retrieved from /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py
[2023-06-24T21:42:49.990+0000] {processor.py:176} INFO - Processing /opt/airflow/dags/airflow_dags/batch_etl_pipeline.py took 0.431 seconds
